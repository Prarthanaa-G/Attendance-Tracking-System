{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mediapipe Installation"
      ],
      "metadata": {
        "id": "N1w1CqLNUsTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhhJ41-eghFx",
        "outputId": "eb7071bb-c38f-4f80-8bee-56b6d242e8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.20)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEmjUlbugM72",
        "outputId": "2bb9f75a-fc44-4102-aa40-64604baf0820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video Preprocessing"
      ],
      "metadata": {
        "id": "2auQmIA0NZ1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/newdata\"\n",
        "output_path = \"/content/drive/MyDrive/finaloutput\"\n",
        "\n",
        "def alter_speed(frames, factor):\n",
        "    if factor > 1:\n",
        "        return frames[::int(factor)]\n",
        "    elif factor < 1:\n",
        "        return [frame for frame in frames for _ in range(int(1 / factor))]\n",
        "    return frames\n",
        "\n",
        "def crop_frame(frame):\n",
        "    h, w = frame.shape[:2]\n",
        "    return frame[int(h * 0.1):int(h * 0.9), int(w * 0.1):int(w * 0.9)]\n",
        "\n",
        "def add_noise(frame):\n",
        "    noise = np.random.normal(0, 25, frame.shape).astype(np.uint8)\n",
        "    return cv2.add(frame, noise)\n",
        "\n",
        "def apply_blur(frame, kernel_size=5):\n",
        "    return cv2.GaussianBlur(frame, (kernel_size, kernel_size), 0)\n",
        "\n",
        "def extract_keypoints_with_augmentation(video_path, speed_factor=1):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    keypoints_sequence = []\n",
        "    frame_sequence = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frame_sequence.append(frame_rgb)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    altered_frames = alter_speed(frame_sequence, speed_factor)\n",
        "\n",
        "    augmented_frames = []\n",
        "    for frame in altered_frames:\n",
        "        augmented_frames.append(frame)\n",
        "        augmented_frames.append(cv2.flip(frame, 1))\n",
        "\n",
        "    for frame in augmented_frames:\n",
        "        results = pose.process(frame)\n",
        "        if results.pose_landmarks:\n",
        "            keypoints = np.array([[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark]).flatten()\n",
        "            keypoints_sequence.append(keypoints)\n",
        "        else:\n",
        "            keypoints_sequence.append(np.zeros(99))\n",
        "\n",
        "    return np.array(keypoints_sequence)\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "label_map = {}\n",
        "\n",
        "for idx, person in enumerate(sorted(os.listdir(data_path))):\n",
        "    person_folder = os.path.join(data_path, person)\n",
        "    if not os.path.isdir(person_folder):\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing folder: {person_folder}\")\n",
        "    label_map[idx] = person\n",
        "    for video_file in os.listdir(person_folder):\n",
        "        video_path = os.path.join(person_folder, video_file)\n",
        "        if video_file.endswith(('.mp4', '.avi', '.mov')):\n",
        "            print(f\"Processing video: {video_path}\")\n",
        "            keypoints = extract_keypoints_with_augmentation(video_path, speed_factor=1.5)\n",
        "            if keypoints.size > 0:\n",
        "                data.append(keypoints)\n",
        "                labels.append(idx)\n",
        "\n",
        "\n",
        "print(f\"Number of samples loaded: {len(data)}\")\n",
        "print(f\"Number of labels loaded: {len(labels)}\")\n",
        "\n",
        "if len(data) == 0:\n",
        "    raise ValueError(\"No data was loaded. Please check your dataset structure and paths.\")\n",
        "\n",
        "data = np.array(data, dtype=object)\n",
        "labels = np.array(labels)\n",
        "\n",
        "train_data, temp_data, train_labels, temp_labels = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
        "val_data, test_data, val_labels, test_labels = train_test_split(temp_data, temp_labels, test_size=0.5, random_state=42)\n",
        "\n",
        "np.savez_compressed(os.path.join(output_path, \"processed_data.npz\"),\n",
        "                    train_data=train_data, train_labels=train_labels,\n",
        "                    val_data=val_data, val_labels=val_labels,\n",
        "                    test_data=test_data, test_labels=test_labels)\n",
        "\n",
        "print(\"Data preprocessing complete!\")\n",
        "print(f\"Train Samples: {len(train_data)}, Validation Samples: {len(val_data)}, Test Samples: {len(test_data)}\")\n"
      ],
      "metadata": {
        "id": "rc1FpdFZukis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a21291-a98b-4f0e-bb39-95557923bd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing folder: /content/drive/MyDrive/newdata/Prarthana\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/VID20250115105310.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/VID_20250115_102348.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/20250115_105311.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/20250115_105218.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/WhatsApp Video 2025-01-15 at 11.48.53_6b44f21f.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/WhatsApp Video 2025-01-15 at 11.48.58_9541ecde.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/WhatsApp Video 2025-01-15 at 11.49.03_77bf95b8.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/a.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/b.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/c.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of a (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of b.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of WhatsApp Video 2025-01-15 at 11.49.03_77bf95b8.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of VID20250115105310 (2).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of VID_20250115_102348 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of WhatsApp Video 2025-01-15 at 11.48.58_9541ecde.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of WhatsApp Video 2025-01-15 at 11.48 (1).53_6b44f21f.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of 20250115_105218.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of 20250115_105311.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of c.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of a.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of Copy of WhatsApp Video 2025-01-15 at 11.48.58_9541ecde.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of Copy of WhatsApp Video 2025-01-15 at 11.49.03_77bf95b8.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of VID20250115105310 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of VID_20250115_102348.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of WhatsApp Video 2025-01-15 at 11.48.53_6b44f21f.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Prarthana/Copy of VID20250115105310.mp4\n",
            "Processing folder: /content/drive/MyDrive/newdata/Preksha\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/1.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/2.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/3.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/4.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/5.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/6.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/1 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/2 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/3 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/4 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/5 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/6 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/7.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/8.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/Copy of 6 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/Copy of 5 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/Copy of 4.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/Copy of 3.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/Copy of 3 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/Copy of 5.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/Copy of 4 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/Copy of 2 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/Copy of 2.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/Copy of 1.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Preksha/Copy of 1 (1).mp4\n",
            "Processing folder: /content/drive/MyDrive/newdata/Rashmi \n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /20250115_105713.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /20250115_105655.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /VID_20250115_103557.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /VID_20250115_103524.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /VID_20250115_103336.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /VID-20250115-WA0005.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /VID-20250115-WA0004.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /VID-20250115-WA0003.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /VID-20250115-WA0002.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of VID-20250115-WA0005 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of VID_20250115_103524.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of 20250115_105713 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of VID-20250115-WA0002 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of VID-20250115-WA0003 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of VID_20250115_103336.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of VID-20250115-WA0004 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of 20250115_105655 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of VID_20250115_103557 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of VID-20250115-WA0005.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of VID-20250115-WA0004.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of VID-20250115-WA0002.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of VID-20250115-WA0003.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of VID_20250115_103557.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of 20250115_105713.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Rashmi /Copy of 20250115_105655.mp4\n",
            "Processing folder: /content/drive/MyDrive/newdata/Shilpa\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/VID_20250115_103153.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/VID_20250115_102957.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/VID_20250115_102759.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/VID20250115102818.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/VID20250115102758.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/VID20250115102725.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/20250115_105334.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/20250115_105351.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID20250115102909 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID20250115103152 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID_20250115_102759.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID20250115102725.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID20250115102818 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID20250115105350 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID_20250115_103153.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID20250115102758.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID_20250115_102957.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID20250115105334 (1).mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of 20250115_105334.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of 20250115_105351.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID20250115102909.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID20250115105350.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID20250115103152.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID20250115105334.mp4\n",
            "Processing video: /content/drive/MyDrive/newdata/Shilpa/Copy of VID20250115102818.mp4\n",
            "Number of samples loaded: 102\n",
            "Number of labels loaded: 102\n",
            "Data preprocessing complete!\n",
            "Train Samples: 71, Validation Samples: 15, Test Samples: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data = np.load('/content/drive/MyDrive/finaloutput/processed_data.npz',allow_pickle=True)\n",
        "print(data.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bOH_xLx_CtS",
        "outputId": "58963a87-3179-40bf-ee88-cd37dbb27984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeysView(NpzFile '/content/drive/MyDrive/finaloutput/processed_data.npz' with keys: train_data, train_labels, val_data, val_labels, test_data...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks9UduTmAAb6",
        "outputId": "aaaadaa9-f70e-44ba-e911-141a17e00910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KeysView(NpzFile '/content/drive/MyDrive/finaloutput/processed_data.npz' with keys: train_data, train_labels, val_data, val_labels, test_data...)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=data['train_data']\n",
        "train_labels = data['train_labels']\n",
        "val_data = data['val_data']\n",
        "val_labels = data['val_labels']\n",
        "test_data = data['test_data']\n",
        "test_labels = data['test_labels']\n",
        "\n",
        "print(\"Train data shape:\", train_data.shape)\n",
        "print(\"Train label shape:\", train_labels.shape)\n",
        "print(\"Validation data shape:\", val_data.shape)\n",
        "print(\"Validation label shape:\", val_labels.shape)\n",
        "print(\"Test data shape:\", test_data.shape)\n",
        "print(\"Test label shape:\", test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NZ9ytXC_hLY",
        "outputId": "16a1efa4-74e2-4624-805e-2f94904db00b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (71,)\n",
            "Train label shape: (71,)\n",
            "Validation data shape: (15,)\n",
            "Validation label shape: (15,)\n",
            "Test data shape: (16,)\n",
            "Test label shape: (16,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sequence = train_data[0]\n",
        "print(\"Type of first sequence:\", type(sequence))\n",
        "print(\"Shape of first sequence (if array):\", sequence.shape if isinstance(sequence, np.ndarray) else \"Not an array\")\n",
        "\n",
        "for i in range(3):\n",
        "    print(f\"Sequence {i} length: {len(train_data[i]) if hasattr(train_data[i], '__len__') else 'Unknown'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkAzCNfkAn6e",
        "outputId": "ea2056ca-14da-44a3-db12-e621d850a708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of first sequence: <class 'numpy.ndarray'>\n",
            "Shape of first sequence (if array): (408, 99)\n",
            "Sequence 0 length: 408\n",
            "Sequence 1 length: 548\n",
            "Sequence 2 length: 452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(f\"Sequence {i} length: {len(train_data[i]) if hasattr(train_data[i], '__len__') else 'Unknown'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLACPQeACa9a",
        "outputId": "1465902a-24d3-48fe-cb96-f543d468b0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence 0 length: 408\n",
            "Sequence 1 length: 548\n",
            "Sequence 2 length: 452\n",
            "Sequence 3 length: 432\n",
            "Sequence 4 length: 422\n",
            "Sequence 5 length: 452\n",
            "Sequence 6 length: 508\n",
            "Sequence 7 length: 406\n",
            "Sequence 8 length: 432\n",
            "Sequence 9 length: 446\n",
            "Sequence 10 length: 412\n",
            "Sequence 11 length: 374\n",
            "Sequence 12 length: 356\n",
            "Sequence 13 length: 410\n",
            "Sequence 14 length: 422\n",
            "Sequence 15 length: 450\n",
            "Sequence 16 length: 528\n",
            "Sequence 17 length: 558\n",
            "Sequence 18 length: 446\n",
            "Sequence 19 length: 412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_length = 350\n",
        "padded_train_data = pad_sequences(train_data, maxlen=max_length, dtype='float32', padding='post', truncating='post')\n",
        "padded_val_data = pad_sequences(val_data, maxlen=max_length, dtype='float32', padding='post', truncating='post')\n",
        "padded_test_data = pad_sequences(test_data, maxlen=max_length, dtype='float32', padding='post', truncating='post')\n",
        "\n",
        "print(\"Padded train data shape:\", padded_train_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_rSpNrTC23u",
        "outputId": "98fc97ac-c110-4471-b796-c488ee717da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded train data shape: (71, 350, 99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Padded val data shape:\", padded_val_data.shape)\n",
        "print(\"Padded test data shape:\", padded_test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V7qSAr_DOoT",
        "outputId": "b30f3856-6c78-4242-b74f-9ef1e530082c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded val data shape: (15, 350, 99)\n",
            "Padded test data shape: (16, 350, 99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "padded_train_data = padded_train_data / np.max(padded_train_data)\n",
        "padded_val_data = padded_val_data / np.max(padded_val_data)\n",
        "padded_test_data = padded_test_data / np.max(padded_test_data)\n"
      ],
      "metadata": {
        "id": "qqKIkr31DcxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Sample labels:\", train_labels[:10])\n",
        "print(\"Type of labels:\", type(train_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SL_zpdFEHCU",
        "outputId": "1bf07b30-a29e-47d1-eb7d-448a340cc4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample labels: [0 3 2 1 2 0 3 2 1 0]\n",
            "Type of labels: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "num_classes = len(np.unique(train_labels))\n",
        "\n",
        "train_labels_one_hot = to_categorical(train_labels, num_classes)\n",
        "val_labels_one_hot = to_categorical(val_labels, num_classes)\n",
        "test_labels_one_hot = to_categorical(test_labels, num_classes)\n",
        "\n",
        "print(\"One-hot encoded train labels shape:\", train_labels_one_hot.shape)\n",
        "print(\"One-hot encoded validation labels shape:\", val_labels_one_hot.shape)\n",
        "print(\"One-hot encoded test labels shape:\", test_labels_one_hot.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUXeieEAEenL",
        "outputId": "c61aefd0-30e7-4d57-bc23-7f4b80f119c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot encoded train labels shape: (71, 4)\n",
            "One-hot encoded validation labels shape: (15, 4)\n",
            "One-hot encoded test labels shape: (16, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(350, 99)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Conv1D(128, kernel_size=5, activation='elu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.4),\n",
        "    Conv1D(64, kernel_size=5, activation='elu', kernel_regularizer=l2(0.02)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.4),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    padded_train_data, train_labels_one_hot,\n",
        "    validation_data=(padded_val_data, val_labels_one_hot),\n",
        "    epochs=50,\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(padded_test_data, test_labels_one_hot)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "model.save('trained_model11.h5')\n",
        "print(\"Model saved as 'trained_model11.h5'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wLdO0TdNslG",
        "outputId": "0958e369-1284-4460-eed4-504ed0d78cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.3870 - loss: 3.1605 - val_accuracy: 0.2667 - val_loss: 3.0883\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.2717 - loss: 3.0786 - val_accuracy: 0.2667 - val_loss: 3.0218\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.2791 - loss: 3.1798 - val_accuracy: 0.6667 - val_loss: 2.8076\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.4653 - loss: 2.7955 - val_accuracy: 0.4000 - val_loss: 2.7888\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.4850 - loss: 2.7193 - val_accuracy: 0.5333 - val_loss: 2.6173\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.5447 - loss: 2.4859 - val_accuracy: 0.6000 - val_loss: 2.4147\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.7502 - loss: 2.1811 - val_accuracy: 0.7333 - val_loss: 2.3209\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.5699 - loss: 2.2635 - val_accuracy: 0.7333 - val_loss: 2.1799\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.7672 - loss: 1.9855 - val_accuracy: 0.7333 - val_loss: 2.0898\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.7622 - loss: 1.9683 - val_accuracy: 0.8000 - val_loss: 2.0122\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7876 - loss: 1.7369 - val_accuracy: 0.8000 - val_loss: 1.8391\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7987 - loss: 1.6842 - val_accuracy: 0.8000 - val_loss: 1.8616\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9065 - loss: 1.5132 - val_accuracy: 0.8000 - val_loss: 1.8454\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9397 - loss: 1.4645 - val_accuracy: 0.8000 - val_loss: 1.6832\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8426 - loss: 1.4022 - val_accuracy: 0.8000 - val_loss: 1.7803\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9293 - loss: 1.2828 - val_accuracy: 0.8667 - val_loss: 1.7330\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9660 - loss: 1.2151 - val_accuracy: 0.8000 - val_loss: 1.3590\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9660 - loss: 1.1400 - val_accuracy: 0.8667 - val_loss: 1.5908\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9529 - loss: 1.1648 - val_accuracy: 0.6667 - val_loss: 2.1624\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9241 - loss: 1.1173 - val_accuracy: 0.8000 - val_loss: 2.0072\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9647 - loss: 1.0338 - val_accuracy: 0.8667 - val_loss: 1.7526\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9573 - loss: 0.9769 - val_accuracy: 0.8000 - val_loss: 1.6400\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9854 - loss: 0.9429 - val_accuracy: 0.8000 - val_loss: 1.6687\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9677 - loss: 0.8776 - val_accuracy: 0.8667 - val_loss: 1.4135\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.8154 - val_accuracy: 0.8667 - val_loss: 1.3590\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9712 - loss: 0.8235 - val_accuracy: 0.8667 - val_loss: 1.4871\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9785 - loss: 0.7721 - val_accuracy: 0.8667 - val_loss: 1.4818\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9953 - loss: 0.7119 - val_accuracy: 0.8667 - val_loss: 1.5892\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.6881 - val_accuracy: 0.8667 - val_loss: 1.3168\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.6519 - val_accuracy: 0.8667 - val_loss: 1.3525\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9892 - loss: 0.6501 - val_accuracy: 0.8000 - val_loss: 1.2606\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9576 - loss: 0.6613 - val_accuracy: 0.8000 - val_loss: 1.1911\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9880 - loss: 0.5835 - val_accuracy: 0.8667 - val_loss: 1.0497\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9767 - loss: 0.5808 - val_accuracy: 1.0000 - val_loss: 0.6896\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9576 - loss: 0.5753 - val_accuracy: 0.8000 - val_loss: 1.3288\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9767 - loss: 0.5395 - val_accuracy: 0.8667 - val_loss: 0.9304\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9819 - loss: 0.5175 - val_accuracy: 0.8667 - val_loss: 1.2840\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9020 - loss: 0.7199 - val_accuracy: 0.8000 - val_loss: 1.0327\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9785 - loss: 0.4843 - val_accuracy: 1.0000 - val_loss: 0.5371\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9840 - loss: 0.4557 - val_accuracy: 0.8667 - val_loss: 0.6737\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9833 - loss: 0.4471 - val_accuracy: 0.8667 - val_loss: 0.7913\n",
            "Epoch 42/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9736 - loss: 0.4196 - val_accuracy: 0.8667 - val_loss: 0.6970\n",
            "Epoch 43/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.9642 - loss: 0.4226 - val_accuracy: 0.8667 - val_loss: 0.7901\n",
            "Epoch 44/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9628 - loss: 0.4122 - val_accuracy: 0.8000 - val_loss: 1.0744\n",
            "Epoch 45/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9680 - loss: 0.4060 - val_accuracy: 0.8000 - val_loss: 1.0875\n",
            "Epoch 46/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.3326 - val_accuracy: 0.8000 - val_loss: 0.9377\n",
            "Epoch 47/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9736 - loss: 0.3469 - val_accuracy: 0.8667 - val_loss: 0.7301\n",
            "Epoch 48/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9689 - loss: 0.3302 - val_accuracy: 0.8667 - val_loss: 0.6397\n",
            "Epoch 49/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.9953 - loss: 0.3068 - val_accuracy: 0.8667 - val_loss: 0.7882\n",
            "Epoch 50/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.2924 - val_accuracy: 0.8000 - val_loss: 1.1351\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8750 - loss: 1.1781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.1780929565429688, Test Accuracy: 0.875\n",
            "Model saved as 'trained_model11.h5'\n"
          ]
        }
      ]
    }
  ]
}